{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Water Quality and Potability Classification\n",
    "  \n",
    "#### [Dataset URL](https://www.kaggle.com/datasets/uom190346a/water-quality-and-potability)\n",
    "  \n",
    "## Opis zbioru danych\n",
    "\n",
    "Ten zbiór danych zawiera pomiary jakości wody oraz oceny dotyczące jej zdatności do spożycia przez ludzi, czyli potencjał pitności. Głównym celem tego zbioru danych jest dostarczenie wglądu w parametry jakości wody i pomoc w określeniu, czy woda jest zdatna do spożycia. Każdy wiersz w zbiorze danych reprezentuje próbkę wody z określonymi cechami, a kolumna \"Potability\" wskazuje, czy woda jest odpowiednia do spożycia. Głównym celem tego zbioru danych jest ocena i przewidywanie potencjału potabilności wody na podstawie cech jakości wody. Może być używany do oceny bezpieczeństwa i odpowiedniości źródeł wody do spożycia przez ludzi, podejmowania świadomych decyzji dotyczących uzdatniania wody oraz zapewnienia zgodności z normami jakości wody.\n",
    "\n",
    "## Opis cech\n",
    "\n",
    "- pH: Poziom pH wody.\n",
    "- Hardness: Twardość wody, miara zawartości minerałów.\n",
    "- Solids: Całkowita zawartość substancji rozpuszczonych w wodzie.\n",
    "- Chloramines: Stężenie chloramin w wodzie.\n",
    "- Sulfate: Stężenie siarczanów w wodzie.\n",
    "- Conductivity: Przewodność elektryczna wody.\n",
    "- Organic_carbon: Zawartość węgla organicznego w wodzie.\n",
    "- Trihalomethanes: Stężenie trihalometanów w wodzie.\n",
    "- Turbidity: Poziom mętności, miara klarowności wody.\n",
    "- Potability: Zmienna celu; wskazuje zdatność do spożycia wody, przyjmując wartości 1 (zdatna do spożycia - \"potable\") i 0 (niezdatna do spożycia - \"not potable).\n",
    "\n",
    "## Parametry zbioru danych\n",
    "\n",
    "- Liczba rekordów: 3276\n",
    "- Liczba cech: 9\n",
    "- Dane brakujące: Tak (kolumny: pH, Sulfate and Trihalomethanes)\n",
    "- Dane odstające: Tak (ok. 1.22% całego zbioru danych) \n",
    "- Typ problemu: Klasyfikacja (Potability - No (0), Yes (1))\n",
    "\n",
    "## Rozkład klas\n",
    "\n",
    "| Klasa | Liczba rekordów | Rozkład procentowy |\n",
    "|-------|-----------------|--------------------|\n",
    "| 0     | 1998            | 60.99%             |\n",
    "| 1     | 1278            | 39.01%             |"
   ],
   "id": "99d9afe048032a69"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importowanie bibliotek",
   "id": "1564c7a598330ba1"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-02T19:30:46.790389Z",
     "start_time": "2024-06-02T19:30:43.754609Z"
    }
   },
   "source": [
    "import pickle\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "from deap import base, creator, tools, algorithms\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Załadowanie zmiennych\n",
    "\n",
    "Zmienne zostają załadowane z pliku wygenerowanego z notebooka DataAnalysis.ipynb przy pomocy biblioteki pickle, służącej do serializacji oraz deserializacji danych. Wybrano dane, które osiągnęły najlepsze wyniki podczas 2 etapu - tworzenia i trenowania modeli."
   ],
   "id": "6b4594b797ec8ba3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T19:30:47.636942Z",
     "start_time": "2024-06-02T19:30:46.791389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('data_dump/normalizedStdInterpolateVars.pkl', 'rb') as f:\n",
    "    normalized_std_interpolate = pickle.load(f)\n",
    "    scaler_std_interpolate = pickle.load(f)"
   ],
   "id": "98c6b6cef0c3e12c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Funkcje do podziału zbioru danych\n",
    "\n",
    "Utworzono dwie funkcje do tworzenia podziału danych. Split_df_train_test odpowiada za podział danych na dwa zbiory: testowy i treningowy. Dane są dzielone z równomiernym podziałem klas, aby zapobiec sytuacji, w której podczas podziału danych, przydzielono do zbioru treningowego tylko jedną klasę danych. "
   ],
   "id": "dbc821621c1463e4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T19:30:47.652943Z",
     "start_time": "2024-06-02T19:30:47.637943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_df_train_test(data, test_size, seed):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    unique_labels = data['Potability'].unique()\n",
    "    label_counts = data['Potability'].value_counts()\n",
    "\n",
    "    test_indices = []\n",
    "\n",
    "    for label in unique_labels:\n",
    "        num_label_samples = label_counts[label]\n",
    "        num_test_samples = int(test_size * num_label_samples)\n",
    "        label_indices = data.index[data['Potability'] == label].tolist()\n",
    "        label_test_indices = np.random.choice(label_indices, size=num_test_samples, replace=False)\n",
    "        test_indices.extend(label_test_indices)\n",
    "\n",
    "    train_indices = np.setdiff1d(data.index, test_indices)\n",
    "\n",
    "    train_set = data.loc[train_indices]\n",
    "    test_set = data.loc[test_indices]\n",
    "\n",
    "    return train_set, test_set"
   ],
   "id": "229410bbd9ed5efe",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Funkcja do obliczania metryki F1-score",
   "id": "fe70e3d2e469a70"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T19:30:47.668942Z",
     "start_time": "2024-06-02T19:30:47.653946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_f1_score(y_true, y_pred):\n",
    "    true_positives = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    true_negatives = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    false_positives = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    false_negatives = np.sum((y_true == 1) & (y_pred == 0))\n",
    "\n",
    "    precision_positives = true_positives / (true_positives + false_positives)\n",
    "    recall_positives = true_positives / (true_positives + false_negatives)\n",
    "    f1_score_positives = 2 * (precision_positives * recall_positives) / (precision_positives + recall_positives)\n",
    "\n",
    "    precision_negatives = true_negatives / (true_negatives + false_negatives)\n",
    "    recall_negatives = true_negatives / (true_negatives + false_positives)\n",
    "    f1_score_negatives = 2 * (precision_negatives * recall_negatives) / (precision_negatives + recall_negatives)\n",
    "\n",
    "    f1_score = (f1_score_positives + f1_score_negatives) / 2\n",
    "    return f1_score"
   ],
   "id": "1fcc8cb72ec1fc3",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Split danych\n",
    "\n",
    "Podzielenie danych przy pomocy funkcji \"split_df_train_test\""
   ],
   "id": "e717751751c9c936"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T19:30:47.684945Z",
     "start_time": "2024-06-02T19:30:47.669943Z"
    }
   },
   "cell_type": "code",
   "source": "train_std_interpolate, test_std_interpolate = split_df_train_test(normalized_std_interpolate, 0.2, 123)",
   "id": "fe2274776124ccdc",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Podział klas po splicie - test/train",
   "id": "9a44526aeccc3b8d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T19:30:47.700943Z",
     "start_time": "2024-06-02T19:30:47.685944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_class_counts = train_std_interpolate['Potability'].value_counts(normalize=True) * 100\n",
    "test_class_counts = test_std_interpolate['Potability'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Train set:\")\n",
    "print(train_class_counts)\n",
    "print(\"\\nTest set:\")\n",
    "print(test_class_counts)"
   ],
   "id": "d760a98781931b74",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:\n",
      "Potability\n",
      "0    60.983982\n",
      "1    39.016018\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test set:\n",
      "Potability\n",
      "0    61.009174\n",
      "1    38.990826\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## SVM - Scikit-Learn",
   "id": "4700dedd081c0230"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T19:30:47.716943Z",
     "start_time": "2024-06-02T19:30:47.701944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SVMClassifierWrapper:\n",
    "\n",
    "    def __init__(self, train_set, test_set):\n",
    "        self.train_set = train_set.iloc[:, :-1]\n",
    "        self.test_set = test_set.iloc[:, :-1]\n",
    "        self.train_label = train_set.iloc[:, -1]\n",
    "        self.test_label = test_set.iloc[:, -1]\n",
    "        self.model = None\n",
    "        self.history = None\n",
    "        self.test_pred = None\n",
    "        self.hof = None\n",
    "        self.best_optuna_trial = None\n",
    "        self._create_model()\n",
    "\n",
    "    def _create_model(self):\n",
    "        self.model = SVC(random_state=42)\n",
    "\n",
    "    def evalSVMModel(self, individual, optimize_f1_score):\n",
    "        C, degree, coef0 = individual\n",
    "        degree = int(degree)\n",
    "        C = max(C, 0.1)\n",
    "        coef0 = max(coef0, 0)\n",
    "        model = SVC(C=C, degree=degree, coef0=coef0, random_state=42)\n",
    "        model.fit(self.train_set, self.train_label)\n",
    "        predictions = model.predict(self.test_set)\n",
    "\n",
    "        if optimize_f1_score:\n",
    "            score = calculate_f1_score(self.test_label, predictions)\n",
    "        else:\n",
    "            score = accuracy_score(self.test_label, predictions)\n",
    "\n",
    "        return score,\n",
    "\n",
    "    def train_model_with_ga(self, optimize_f1_score=False):\n",
    "        if not hasattr(creator, 'FitnessMax'):\n",
    "            creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "        if not hasattr(creator, 'Individual'):\n",
    "            creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "        toolbox = base.Toolbox()\n",
    "\n",
    "        toolbox.register(\"attr_C\", random.uniform, 0.1, 30)\n",
    "        toolbox.register(\"attr_degree\", random.randint, 1, 10)\n",
    "        toolbox.register(\"attr_coef0\", random.uniform, 0, 20)\n",
    "\n",
    "        toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
    "                         (toolbox.attr_C, toolbox.attr_degree, toolbox.attr_coef0), n=1)\n",
    "\n",
    "        toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "        toolbox.register(\"evaluate\", self.evalSVMModel, optimize_f1_score=optimize_f1_score)\n",
    "        toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "        toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=1, indpb=0.2)\n",
    "        toolbox.register(\"select\", tools.selTournament, tournsize=5)\n",
    "\n",
    "        pop = toolbox.population(n=100)\n",
    "        self.hof = tools.HallOfFame(1)\n",
    "        stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "        stats.register(\"avg\", np.mean)\n",
    "        stats.register(\"min\", np.min)\n",
    "        stats.register(\"max\", np.max)\n",
    "\n",
    "        #toolbox.register(\"map\", futures.map) <- scoop library\n",
    "        pop, logbook = algorithms.eaMuPlusLambda(pop, toolbox, mu=50, lambda_=50, cxpb=0.5, mutpb=0.2, ngen=5,\n",
    "                                                 stats=stats, halloffame=self.hof, verbose=True)\n",
    "\n",
    "        best_individual = tools.selBest(pop, 1)[0]\n",
    "\n",
    "        self.model = SVC(C=best_individual[0], degree=int(best_individual[1]), coef0=best_individual[2], kernel=\"poly\", random_state=42)\n",
    "        self.model.fit(self.train_set, self.train_label)\n",
    "\n",
    "    def optuna_objective(self, trial, optimize_f1_score):\n",
    "        C = trial.suggest_float(\"C\", 0.1, 30)\n",
    "        degree = trial.suggest_int(\"degree\", 1, 10)\n",
    "        coef0 = trial.suggest_float(\"coef0\", 0, 20)\n",
    "\n",
    "        model = SVC(C=C, degree=degree, coef0=coef0, kernel=\"poly\", random_state=42)\n",
    "        model.fit(self.train_set, self.train_label)\n",
    "        predictions = model.predict(self.test_set)\n",
    "\n",
    "        if optimize_f1_score:\n",
    "            score = calculate_f1_score(self.test_label, predictions)\n",
    "        else:\n",
    "            score = accuracy_score(self.test_label, predictions)\n",
    "\n",
    "        return score\n",
    "\n",
    "    def train_model_with_optuna(self, optimize_f1_score=False, n_trials=5):\n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(lambda trial: self.optuna_objective(trial, optimize_f1_score), n_jobs=-1, n_trials=n_trials)\n",
    "\n",
    "        self.best_optuna_trial = study.best_trial\n",
    "\n",
    "        self.model = SVC(C=self.best_optuna_trial.params[\"C\"], degree=self.best_optuna_trial.params[\"degree\"],\n",
    "                         coef0=self.best_optuna_trial.params[\"coef0\"], kernel=\"poly\", random_state=42)\n",
    "        self.model.fit(self.train_set, self.train_label)\n",
    "\n",
    "    def get_deap_best_individual(self):\n",
    "        return self.hof[0]\n",
    "    \n",
    "    def get_optuna_best_result(self):\n",
    "        return self.best_optuna_trial"
   ],
   "id": "f21965f13ddc0e43",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Trenowanie modelu SVM - optymalizacja hiperparametrów za pomocą algorytmu genetycznego",
   "id": "19772d723544f6be"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T19:31:52.555542Z",
     "start_time": "2024-06-02T19:30:47.717943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_best_individual(model):\n",
    "    best_individual = model.get_deap_best_individual()\n",
    "    print(\"Best hiperparameters:\")\n",
    "    print(f\"C: {best_individual[0]}\")\n",
    "    print(f\"Degree: {best_individual[1]}\")\n",
    "    print(f\"Coef0: {best_individual[2]}\")\n",
    "\n",
    "print(\"DEAP - Accuracy: \\n\")\n",
    "start_time = time.time()\n",
    "SVM_model_accuracy_optimizing_DEAP = SVMClassifierWrapper(train_std_interpolate, test_std_interpolate)\n",
    "SVM_model_accuracy_optimizing_DEAP.train_model_with_ga(optimize_f1_score=False)\n",
    "print_best_individual(SVM_model_accuracy_optimizing_DEAP)\n",
    "end_time = time.time()\n",
    "print(f\"DEAP - Execution time for accuracy: {format(end_time - start_time, '.2f')} seconds\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# print(\"DEAP - F1 Score: \\n\")\n",
    "# start_time = time.time()\n",
    "# SVM_model_f1score_optimizing_DEAP = SVMClassifierWrapper(train_std_interpolate, test_std_interpolate)\n",
    "# SVM_model_f1score_optimizing_DEAP.train_model_with_ga(optimize_f1_score=True)\n",
    "# print_best_individual(SVM_model_f1score_optimizing_DEAP)\n",
    "# end_time = time.time()\n",
    "# print(f\"DEAP - Execution time for F1 Score: {format(end_time - start_time, '.2f')} seconds\")"
   ],
   "id": "8f6dbe86484ea8c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEAP - Accuracy: \n",
      "\n",
      "gen\tnevals\tavg     \tmin     \tmax     \n",
      "0  \t100   \t0.675795\t0.646789\t0.695719\n",
      "1  \t31    \t0.686667\t0.678899\t0.695719\n",
      "2  \t31    \t0.692997\t0.680428\t0.695719\n",
      "3  \t40    \t0.695657\t0.692661\t0.695719\n",
      "4  \t38    \t0.695719\t0.695719\t0.695719\n",
      "5  \t32    \t0.695719\t0.695719\t0.695719\n",
      "Best hiperparameters:\n",
      "C: 2.2842021177940457\n",
      "Degree: 10\n",
      "Coef0: 15.490211907592483\n",
      "DEAP - Execution time for accuracy: 64.82 seconds\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Trenowanie modelu SVM - optymalizacja hiperparametrów za pomocą biblioteki Optuna",
   "id": "4c3e83c9f4ac653e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-02T19:31:52.556540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_best_optuna_result(model):\n",
    "    best_trial = model.get_optuna_best_result()\n",
    "    print(\"Best hiperparameters:\")\n",
    "    for key, value in best_trial.params.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "        \n",
    "print(\"Optuna - Accuracy: \\n\")\n",
    "start_time = time.time()\n",
    "SVM_model_accuracy_optimizing_optuna = SVMClassifierWrapper(train_std_interpolate, test_std_interpolate)\n",
    "SVM_model_accuracy_optimizing_optuna.train_model_with_optuna(optimize_f1_score=False)\n",
    "print_best_optuna_result(SVM_model_accuracy_optimizing_optuna)\n",
    "end_time = time.time()\n",
    "print(f\"Optuna - Execution time for Accuracy: {format(end_time - start_time, '.2f')} seconds\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# print(\"Optuna - F1 Score: \\n\")\n",
    "# start_time = time.time()\n",
    "# SVM_model_f1score_optimizing_optuna = SVMClassifierWrapper(train_std_interpolate, test_std_interpolate)\n",
    "# SVM_model_f1score_optimizing_optuna.train_model_with_optuna(optimize_f1_score=True)\n",
    "# print_best_optuna_result(SVM_model_f1score_optimizing_optuna)\n",
    "# end_time = time.time()\n",
    "# print(f\"Optuna - Execution time for F1 Score: {format(end_time - start_time, '.2f')} seconds\")"
   ],
   "id": "9734fe3259787f5a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-02 21:31:52,558] A new study created in memory with name: no-name-f1626d0f-f11d-45d6-bd7c-ada4c731d434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna - Accuracy: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-02 21:31:53,872] Trial 3 finished with value: 0.6743119266055045 and parameters: {'C': 13.881195819278206, 'degree': 4, 'coef0': 0.5679374802270609}. Best is trial 3 with value: 0.6743119266055045.\n",
      "[I 2024-06-02 21:33:02,570] Trial 4 finished with value: 0.6039755351681957 and parameters: {'C': 25.37964772395835, 'degree': 10, 'coef0': 6.806003366524185}. Best is trial 3 with value: 0.6743119266055045.\n"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
